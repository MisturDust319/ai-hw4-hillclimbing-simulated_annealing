{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# AI Homework 3: Comparing Search Algorithms\nStan Slupecki\n\n## Introduction\n\nOne of the cornerstones of AI is using search algorithms. Here we compare two search algorithms: iterative deepening and a* search. In this project there effectiveness is measured by how efficiently they solve an 8-block sliding puzzle.\n\nIterative deepening builds on another search algorithm, depth-limited search. Depth limited itself derives from depth first search, a search algorithm where the deepest possible solutions are explored first. Depth limited search's strength is it uses very limited system memory. However, it is a risky strategy for two reasons. First, the first solution found is probably not the most efficient solution. Since this explores the deepest solution first, and shallow solutions are more efficient, the first solution found won't likely be a shallow one. The second problem with a depth first search is difficulty determining an end point. Depth limited search fixes this by performing a depth first search that will stop searching at specified solution depth. It can return a default value if needed. Iterative deepening runs a depth first search repeatedly until a solution is found, incrementally increasing the depth the depth limited search, and re-running the search. This guarantees a solution with a depth limited search, but also ensures it will be found at the shallowest possible depth.\n\nA\\* is a varient of Dijkstra's algorithm. Dijkstra's algorithm computes the shortest path between two nodes in a graph. Starting at the starting node, a node is selected, and the cost of the path to each of the nodes neighbors is calculated and each neighboring node is stored in a priority queue. Priority in the queue is defined such that the nodes with shorter paths are stored first in the queue. The first element in this queue is popped, and it's neighbor's paths are computed and stored in the queue. This process continues in this manner until the end node is reached, and a result is returned. More for when the algorithm is used in search algorithms, if the queue is empty, then the search terminates. A\\* builds on this by using a heuristic that estimates how close the current state is to the end state, and adding it to the path cost before storing the node in the priority queue. Assuming the heuristic function is well designed, a\\* has a reputation for being very efficient.\n\n## Discusion of solution\n\nFor both problems, I decided to use the pre-made AIMA Python code in conjunction with the example code supplied with the homework assignment.\n\nThe AIMA search functions require an object who's class inherits from AIMA's Problem class. This Problem class models the problem you're trying to solve, in this case, the slider puzzle. The advantage of using AIMA's Problem class is, assuming the child class properly models the problem, the same Problem object can be passed to any of AIMA's search functions without modification. This greatly simplifies comparing two search functions, as the problem model is the same for all AIMA search functions. To use implement a child class of the Problem class, I had to override the following virtual methods (besides the \\__init\\__ function): actions, result, and goal_test.\n\nActions is a method that is passed a state, and generates an iterable of legal actions that can be performed in the given state. Since I wanted to use the premade example code, which doesn't split up finding actions from generating new solutions, I iterated over a list of possible directions and used the example code to generate a new solution in that direction. If a new valid solution was generated, then that direction was yielded as a valid action.\n\nResult takes a state and a legal action, and generates a new state representing a possible solution. In this case, state represented a 8-puzzle board configuration, and action represented a possible direction that a piece could be moved to. I chose to use the apply_action() function supplied in the example code. This takes a board configuration and a direction and moves the empty slot of the 8-puzzle in that direction.\n\nThe goal_test method is passed the current state and returns true if the goal state has been reached. I passed the state, which represents a board configuration, to the goal_test() function supplied in the example code. This checks if the slider puzzle is solved, and returns true if it has been, false otherwise.\n\n## Testing Design and Expected Results\n\n### Testing Design\n\nEach search algorithm was tested with the same methods, though the setup for the a* search was slightly more involved. \n\nFirst, each search algorithm is presented with a randomly generated 8-puzzle to solve.\n\nBoth search algorithms were tested with Jupyter's timeit magic command. This is a utility built into Jupyter that will compute the mean execution time of a function. In this case, I specified for 3 runs of each search function using the \"-r 3\" option. This returns time in seconds and milliseconds, the main metric of this project.\n\nLastly, the a\\* search required a heuristic function. I passed a function that calculates \"Manhattan Distance\" for the tiles. The Manhattan Distance function computes the sum of the horizontal and vertical distance between a tile's current position and its intended position, then sums the value for each tile into one value. This value is used to estimate how close the current state is to the goal state. This value is added to the current node's path length to create an estimate of how efficient the current path is.\n\n### Expected Results\n\nI expect a* to outperform iterative deepening.\n\nIterative deepening is a simpler algorithm. It's main advantage is it doesn't store much data when peforming a search. This makes it a good option for simpler systems with limited system resources. However, it is quite capable of generating overly complicated solutions, if it finds one at all.\n\nA\\* on the other hand can be very efficient if an effective heuristic is used. Because a\\* constantly estimates the efficiency of the current path and actively swaps to more efficient paths when presented with the chance, it is much more active in pursuiting the end goal than iterative deepening. This is, of course, dependent on the heuristic used. I used the Manhattan Distance heuristic, a well established, admissable heuristic. That is, it never overestimates the final path cost of the solution path, meaning it won't accidentally mark an efficient solution as inefficient. As such, I feel comfortable in saying it will outperform iterative deepening.\n\n## Test\n\n### Setup"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this allows the python files in the project directory to be imported\nimport sys\nsys.path.append('/home/nbuser/library')\n\nfrom math import floor\nfrom search import iterative_deepening_search, astar_search\nimport eight_puzzle\nimport numpy as np\nimport timeit\n\n# Used to print the solution found by a search function\ndef print_path(node):\n    if node.parent:\n        print_path(node.parent)\n    print(\"Step: \" + str(node.depth + 1))\n    print(node.state[0])\n    print(node.state[1])\n    print(node.state[2])\n    \n# Create a problem object to model an eight puzzle\nproblem = eight_puzzle.EightPuzzleProblem()",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## A* Search"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# The heuristic used is Manhattan distance, a sum of the vertical and horizontal distance\n# between a slider tile's current position and its proper position\ndef manhattan_distance(state):\n    side_length = len(state)\n    # find the length of the side of the puzzle\n\n    distance = 0\n    # the manhattan distance\n    for i in range(side_length):\n        for j in range(side_length):\n            piece = state[i][j]\n            if piece != 0:\n                # find the intended row and column of the current piece\n                original_row = floor((piece-1)/side_length)\n                original_column = (piece-1) % side_length\n\n                # add the current manhattan distance to a cumulative value\n                distance += abs(i - original_row) + abs(j - original_column)\n    return distance",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# run a* three times to get an average runtime\n%timeit -r 3 astar_search(problem, lambda n: manhattan_distance(n.state))",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "2.71 s ± 85.9 ms per loop (mean ± std. dev. of 3 runs, 1 loop each)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this is to demonstrate what a solution looks like\n print_path(astar_search(problem, lambda n: manhattan_distance(n.state)))",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Step: 1\n(0, 1, 2)\n(3, 4, 5)\n(6, 7, 8)\nStep: 2\n(1, 0, 2)\n(3, 4, 5)\n(6, 7, 8)\nStep: 3\n(1, 4, 2)\n(3, 0, 5)\n(6, 7, 8)\nStep: 4\n(1, 4, 2)\n(0, 3, 5)\n(6, 7, 8)\nStep: 5\n(1, 4, 2)\n(5, 3, 0)\n(6, 7, 8)\nStep: 6\n(1, 4, 2)\n(5, 0, 3)\n(6, 7, 8)\nStep: 7\n(1, 0, 2)\n(5, 4, 3)\n(6, 7, 8)\nStep: 8\n(1, 2, 0)\n(5, 4, 3)\n(6, 7, 8)\nStep: 9\n(1, 2, 3)\n(5, 4, 0)\n(6, 7, 8)\nStep: 10\n(1, 2, 3)\n(5, 0, 4)\n(6, 7, 8)\nStep: 11\n(1, 2, 3)\n(0, 5, 4)\n(6, 7, 8)\nStep: 12\n(1, 2, 3)\n(6, 5, 4)\n(0, 7, 8)\nStep: 13\n(1, 2, 3)\n(6, 5, 4)\n(7, 0, 8)\nStep: 14\n(1, 2, 3)\n(6, 0, 4)\n(7, 5, 8)\nStep: 15\n(1, 2, 3)\n(0, 6, 4)\n(7, 5, 8)\nStep: 16\n(1, 2, 3)\n(4, 6, 0)\n(7, 5, 8)\nStep: 17\n(1, 2, 3)\n(4, 0, 6)\n(7, 5, 8)\nStep: 18\n(1, 2, 3)\n(4, 5, 6)\n(7, 0, 8)\nStep: 19\n(1, 2, 3)\n(4, 5, 6)\n(7, 8, 0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Iterative Deepening"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "%timeit -r 3 iterative_deepening_search(problem)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "# this is to demonstrate what a solution looks like\n print_path(iterative_deepening_search(problem))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "## Actual Results\n\n| Search Algorithm | Results  |\n|---|---|\n| Iterative Deepening | n/a  |\n| A* Search| 2.71 s ± 124 ms |\n\nNote that because the initial puzzle configuration is randomly generated, the average time taken to search for a solution may vary slightly.\n\nIn addition, iterative deepening can take a very long time to generate results. I tested my code and AIMA's provided solution for the 8-puzzle (which is genrally more efficient than my solution), and found that it could take around 30 minutes to return results, depending on the puzzle. Currently, the iterative deepening function has been running over two hours in this notebook, and still has yet to return a result.\n\n## Discussion of Results\n\nThe results are in line with my prediction. A* returned a value in about 3 seconds, while over two hours later, the iterative deepening search is still running.\n\n## Conclusion\n\nIn conclusion, a\\* is a highly effective search algorithm. While iterative deepening can be usefull when system resources are limited, it appears for a slider puzzle, this particular search algorithm doesn't work well. Given how the iterative deepening has been running for over two hours, there is even the chance the solution graphs it is currently generating occupy as much if not more memory than a\\*, without returning any results in a timely manner. Given that there are variants of a\\* that use even less system resources, I would consider using them before using iterative deepening for finding a solution to a search problem."
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}